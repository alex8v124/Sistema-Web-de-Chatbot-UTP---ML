{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1_Nfr8fFKHy"
      },
      "outputs": [],
      "source": [
        "# rag_system.ipynb\n",
        "# Asumimos que las variables de data_processing.ipynb (df, preprocess_text) y imports.ipynb (TfidfVectorizer, cosine_similarity) están disponibles.\n",
        "\n",
        "rag_vectorizer = None\n",
        "response_vectors = None\n",
        "\n",
        "# Asegúrate de que 'df' esté cargado y 'Respuesta_Processed' exista\n",
        "if df is not None and 'Respuesta_Processed' in df.columns:\n",
        "    # Crear un vectorizador TF-IDF para las respuestas (la \"base de conocimiento\")\n",
        "    # En producción, solo cargarías este vectorizador y los response_vectors\n",
        "    rag_vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words=None)\n",
        "    response_vectors = rag_vectorizer.fit_transform(df['Respuesta_Processed'])\n",
        "    print(\"Vectorizador RAG y vectores de respuesta creados (o listos para cargar).\")\n",
        "else:\n",
        "    print(\"No se pudo configurar RAG debido a un error de carga de datos o columna faltante.\")\n",
        "\n",
        "\n",
        "# Función para recuperar información relevante\n",
        "def retrieve_info(query, top_n=3):\n",
        "    if rag_vectorizer is None or response_vectors is None:\n",
        "         return [{\"Respuesta_Relevante\": \"Error: Sistema de recuperación no configurado.\", \"Similitud\": 0.0}]\n",
        "\n",
        "    processed_query = preprocess_text(query)\n",
        "    query_vector = rag_vectorizer.transform([processed_query])\n",
        "\n",
        "    # Calcular similitud coseno\n",
        "    similarities = cosine_similarity(query_vector, response_vectors).flatten()\n",
        "\n",
        "    # Obtener los índices de las respuestas más similares\n",
        "    # Asegurarse de que top_n no sea mayor que el número de respuestas disponibles\n",
        "    top_indices = similarities.argsort()[-min(top_n, len(df)):][::-1]\n",
        "\n",
        "    # Recuperar las respuestas originales\n",
        "    retrieved_data = []\n",
        "    for i in top_indices:\n",
        "        retrieved_data.append({\n",
        "            # 'Consulta_Similar': df.loc[i, 'Consulta'], # Opcional, para contexto\n",
        "            'Respuesta_Relevante': df.loc[i, 'Respuesta_SAE'],\n",
        "            'Similitud': float(similarities[i]) # Convertir a float para serialización JSON\n",
        "        })\n",
        "    return retrieved_data\n",
        "\n",
        "# Ejemplo de uso (para probar este notebook individualmente)\n",
        "# if df is not None:\n",
        "#     test_query = \"¿Cuál es la fecha límite para matricularme?\"\n",
        "#     relevant_info = retrieve_info(test_query, top_n=2)\n",
        "#     print(f\"\\nTest Query: '{test_query}'\")\n",
        "#     for item in relevant_info:\n",
        "#         print(f\"  - Respuesta relevante: '{item['Respuesta_Relevante']}' (Similitud: {item['Similitud']:.2f})\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
